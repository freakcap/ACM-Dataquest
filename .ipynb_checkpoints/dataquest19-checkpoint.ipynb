{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 19 columns):\n",
      "Id                    20000 non-null object\n",
      "reassignment_count    20000 non-null int64\n",
      "reopen_count          20000 non-null int64\n",
      "update_count          20000 non-null int64\n",
      "made_sla              20000 non-null bool\n",
      "opened_by             19286 non-null object\n",
      "opened_at             20000 non-null object\n",
      "contact_type          20000 non-null object\n",
      "location              19948 non-null object\n",
      "category              19974 non-null object\n",
      "subcategory           19944 non-null object\n",
      "impact                20000 non-null object\n",
      "urgency               20000 non-null object\n",
      "priority              20000 non-null object\n",
      "assigned_to           14591 non-null object\n",
      "knowledge             20000 non-null bool\n",
      "notify                20000 non-null object\n",
      "vendor                6 non-null object\n",
      "target_days           20000 non-null int64\n",
      "dtypes: bool(2), int64(4), object(13)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "sns.set()\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()\n",
    "\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subcategory 174    5528\n",
       "Subcategory 223    2837\n",
       "Subcategory 175    1524\n",
       "Subcategory 164     962\n",
       "Subcategory 9       698\n",
       "                   ... \n",
       "Subcategory 149       1\n",
       "Subcategory 212       1\n",
       "Subcategory 129       1\n",
       "Subcategory 241       1\n",
       "Subcategory 160       1\n",
       "Name: subcategory, Length: 214, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['subcategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train['opened_at'] = pd.to_datetime(train.opened_at)\n",
    "train['year'] = train['opened_at'].dt.year\n",
    "train['month'] = train['opened_at'].dt.month\n",
    "train['day'] = train['opened_at'].dt.day\n",
    "# train['dayofyear'] = train['opened_at'].dt.dayofyear\n",
    "# train['weekofyear'] = train['opened_at'].dt.weekofyear\n",
    "train['dayofweek'] = train['opened_at'].dt.dayofweek\n",
    "train['hour'] = train['opened_at'].dt.hour\n",
    "train['minute'] = train['opened_at'].dt.minute\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index,row in train.iterrows():\n",
    "    if(row['update_count']!=0):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['vendor']=='Vendor 1' or row['vendor']=='code 8s'):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['knowledge']=='True'):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['made_sla']=='False'):\n",
    "        train.drop(index,inplace=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['vendor'], axis=1, inplace=True)\n",
    "train.drop(['reassignment_count'], axis=1, inplace=True)\n",
    "train.drop(['reopen_count'], axis=1, inplace=True)\n",
    "train.drop(['update_count'], axis=1, inplace=True)\n",
    "# train.drop(['assigned_to'], axis=1, inplace=True)\n",
    "train.drop(['opened_at'], axis=1, inplace=True)\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "train.drop(['made_sla'], axis=1, inplace=True)\n",
    "train.drop(['notify'], axis=1, inplace=True)\n",
    "# train.drop(['year'], axis=1, inplace=True)\n",
    "# train.drop(['contact_type'], axis=1, inplace=True)\n",
    "# train.drop(['dayofweek'], axis=1, inplace=True)\n",
    "# train.drop(['impact'], axis=1, inplace=True)\n",
    "# train.drop(['urgency'], axis=1, inplace=True)\n",
    "# train.drop(['priority'], axis=1, inplace=True)\n",
    "# train.drop(['location'], axis=1, inplace=True)\n",
    "train.drop(['knowledge'], axis=1, inplace=True)\n",
    "\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[['OpBy','opby','opened_by1']] = train.opened_by.str.split(expand=True) \n",
    "train[['loc','location1']] = train.location.str.split(expand=True) \n",
    "train[['cat','category1']] = train.category.str.split(expand=True) \n",
    "train[['scat','subcategory1']] = train.subcategory.str.split(expand=True) \n",
    "train[['assg','assigned_to1']] = train.assigned_to.str.split(expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19989 entries, 0 to 19999\n",
      "Data columns (total 16 columns):\n",
      "contact_type    19989 non-null object\n",
      "impact          19989 non-null object\n",
      "urgency         19989 non-null object\n",
      "priority        19989 non-null object\n",
      "target_days     19989 non-null int64\n",
      "year            19989 non-null int64\n",
      "month           19989 non-null int64\n",
      "day             19989 non-null int64\n",
      "dayofweek       19989 non-null int64\n",
      "hour            19989 non-null int64\n",
      "minute          19989 non-null int64\n",
      "opened_by1      19275 non-null float64\n",
      "location1       19937 non-null float64\n",
      "category1       19963 non-null float64\n",
      "subcategory1    19933 non-null float64\n",
      "assigned_to1    14583 non-null float64\n",
      "dtypes: float64(5), int64(7), object(4)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.drop(['OpBy'], axis=1, inplace=True)\n",
    "train.drop(['opby'], axis=1, inplace=True)\n",
    "train.drop(['opened_by'], axis=1, inplace=True)\n",
    "train['opened_by1'] = train['opened_by1'].astype(float)\n",
    "\n",
    "train.drop(['loc'], axis=1, inplace=True)\n",
    "train.drop(['location'], axis=1, inplace=True)\n",
    "train['location1'] = train['location1'].astype(float)\n",
    "\n",
    "train.drop(['cat'], axis=1, inplace=True)\n",
    "train.drop(['category'], axis=1, inplace=True)\n",
    "train['category1'] = train['category1'].astype(float)\n",
    "\n",
    "train.drop(['scat'], axis=1, inplace=True)\n",
    "train.drop(['subcategory'], axis=1, inplace=True)\n",
    "train['subcategory1'] = train['subcategory1'].astype(float)\n",
    "\n",
    "train.drop(['assg'], axis=1, inplace=True)\n",
    "train.drop(['assigned_to'], axis=1, inplace=True)\n",
    "train['assigned_to1'] = train['assigned_to1'].astype(float)\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[['impact1','imp']] = train['impact'].str.split('-',expand=True)\n",
    "train.drop(['imp'], axis=1, inplace=True)\n",
    "train.drop(['impact'], axis=1, inplace=True)\n",
    "train['impact1'] = train['impact1'].astype(float)\n",
    "\n",
    "train[['urgency1','urg']] = train['urgency'].str.split('-',expand=True)\n",
    "train.drop(['urg'], axis=1, inplace=True)\n",
    "train.drop(['urgency'], axis=1, inplace=True)\n",
    "train['urgency1'] = train['urgency1'].astype(float)\n",
    "\n",
    "train[['priority1','pri']] = train['priority'].str.split('-',expand=True)\n",
    "train.drop(['pri'], axis=1, inplace=True)\n",
    "train.drop(['priority'], axis=1, inplace=True)\n",
    "train['priority1'] = train['priority1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # for index, row in train.iterrows():\n",
    "# #     if(row['opened_by1']==NaN or row['location1']==NaN or row['category1']==NaN or row['subcategory1']==NaN):\n",
    "# #         train.drop(index,inplace=True)\n",
    "\n",
    "\n",
    "train['category1'].fillna((train['category1'].value_counts().idxmax()), inplace=True)\n",
    "train['subcategory1'].fillna((train['subcategory1'].value_counts().idxmax()), inplace=True)\n",
    "train['opened_by1'].fillna((train['opened_by1'].value_counts().idxmax()), inplace=True)\n",
    "train['location1'].fillna((train['location1'].value_counts().idxmax()), inplace=True)\n",
    "train['assigned_to1'].fillna((train['assigned_to1'].value_counts().idxmax()), inplace=True)\n",
    "\n",
    "train = train.dropna(axis = 0, how ='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "# train['made_sla'] = labelencoder.fit_transform(train['made_sla'])\n",
    "# train['assigned_to'] = labelencoder.fit_transform(train['assigned_to'])\n",
    "# train['vendor'] = labelencoder.fit_transform(train['vendor'])\n",
    "train['contact_type'] = labelencoder.fit_transform(train['contact_type'])\n",
    "# train['knowledge'] = labelencoder.fit_transform(train['knowledge'])\n",
    "# train['notify'] = labelencoder.fit_transform(train['notify'])\n",
    "\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# train = onehot_encoder.fit_transform(train)\n",
    "\n",
    "# train = pd.get_dummies(train,prefix_sep = '_',drop_first = True)\n",
    "\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"prepros.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train.corr()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "y = train[\"target_days\"]\n",
    "\n",
    "X = train.drop([\"target_days\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-58da348d3ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from sklearn.ensemble import RandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# lr = RandomForestClassifier(bootstrap=True,n_estimators=50,n_jobs=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifiersifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# lr = RandomForestClassifier(bootstrap=True,n_estimators=50,n_jobs=-1)\n",
    "from xgboost import XGBClassifier\n",
    "lr = XGBClassifier()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error,r2_score\n",
    "y_pred= lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "lmse = mean_squared_log_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "lrmse = np.sqrt(lmse)\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"LMSE:\", lmse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"LRMSE:\", lrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "test['opened_at'] = pd.to_datetime(test.opened_at)\n",
    "test['year'] = test['opened_at'].dt.year\n",
    "test['month'] = test['opened_at'].dt.month\n",
    "test['day'] = test['opened_at'].dt.day\n",
    "# test['dayofyear'] = test['opened_at'].dt.dayofyear\n",
    "# test['weekofyear'] = test['opened_at'].dt.weekofyear\n",
    "test['dayofweek'] = test['opened_at'].dt.dayofweek\n",
    "test['hour'] = test['opened_at'].dt.hour\n",
    "test['minute'] = test['opened_at'].dt.minute\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = test['Id']\n",
    "\n",
    "test.drop(['vendor'], axis=1, inplace=True)\n",
    "test.drop(['reassignment_count'], axis=1, inplace=True)\n",
    "test.drop(['reopen_count'], axis=1, inplace=True)\n",
    "test.drop(['update_count'], axis=1, inplace=True)\n",
    "# test.drop(['assigned_to'], axis=1, inplace=True)\n",
    "test.drop(['opened_at'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['made_sla'], axis=1, inplace=True)\n",
    "test.drop(['notify'], axis=1, inplace=True)\n",
    "# test.drop(['year'], axis=1, inplace=True)\n",
    "# test.drop(['contact_type'], axis=1, inplace=True)\n",
    "# test.drop(['dayofweek'], axis=1, inplace=True)\n",
    "test.drop(['knowledge'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['OpBy','opby','opened_by1']] = test.opened_by.str.split(expand=True) \n",
    "test[['loc','location1']] = test.location.str.split(expand=True) \n",
    "test[['cat','category1']] = test.category.str.split(expand=True) \n",
    "test[['scat','subcategory1']] = test.subcategory.str.split(expand=True) \n",
    "test[['assg','assigned_to1']] = test.assigned_to.str.split(expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['OpBy'], axis=1, inplace=True)\n",
    "test.drop(['opby'], axis=1, inplace=True)\n",
    "test.drop(['opened_by'], axis=1, inplace=True)\n",
    "test['opened_by1'] = test['opened_by1'].astype(float)\n",
    "\n",
    "test.drop(['loc'], axis=1, inplace=True)\n",
    "test.drop(['location'], axis=1, inplace=True)\n",
    "test['location1'] = test['location1'].astype(float)\n",
    "\n",
    "test.drop(['cat'], axis=1, inplace=True)\n",
    "test.drop(['category'], axis=1, inplace=True)\n",
    "test['category1'] = test['category1'].astype(float)\n",
    "\n",
    "test.drop(['scat'], axis=1, inplace=True)\n",
    "test.drop(['subcategory'], axis=1, inplace=True)\n",
    "test['subcategory1'] = test['subcategory1'].astype(float)\n",
    "\n",
    "test.drop(['assg'], axis=1, inplace=True)\n",
    "test.drop(['assigned_to'], axis=1, inplace=True)\n",
    "test['assigned_to1'] = test['assigned_to1'].astype(float)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['impact1','imp']] = test['impact'].str.split('-',expand=True)\n",
    "test.drop(['imp'], axis=1, inplace=True)\n",
    "test.drop(['impact'], axis=1, inplace=True)\n",
    "test['impact1'] = test['impact1'].astype(float)\n",
    "\n",
    "test[['urgency1','urg']] = test['urgency'].str.split('-',expand=True)\n",
    "test.drop(['urg'], axis=1, inplace=True)\n",
    "test.drop(['urgency'], axis=1, inplace=True)\n",
    "test['urgency1'] = test['urgency1'].astype(float)\n",
    "\n",
    "test[['priority1','pri']] = test['priority'].str.split('-',expand=True)\n",
    "test.drop(['pri'], axis=1, inplace=True)\n",
    "test.drop(['priority'], axis=1, inplace=True)\n",
    "test['priority1'] = test['priority1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['category1'].fillna((test['category1'].value_counts().idxmax()), inplace=True)\n",
    "test['subcategory1'].fillna((test['subcategory1'].value_counts().idxmax()), inplace=True)\n",
    "test['opened_by1'].fillna((test['opened_by1'].value_counts().idxmax()), inplace=True)\n",
    "test['location1'].fillna((test['location1'].value_counts().idxmax()), inplace=True)\n",
    "test['assigned_to1'].fillna((test['assigned_to1'].value_counts().idxmax()), inplace=True)\n",
    "\n",
    "\n",
    "test = test.dropna(axis = 0, how ='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "\n",
    "# test['made_sla'] = labelencoder.fit_transform(test['made_sla'])\n",
    "test['contact_type'] = labelencoder.fit_transform(test['contact_type'])\n",
    "\n",
    "# train['assigned_to'] = labelencoder.fit_transform(train['assigned_to'])\n",
    "# train['vendor'] = labelencoder.fit_transform(train['vendor'])\n",
    "# test['knowledge'] = labelencoder.fit_transform(test['knowledge'])\n",
    "# test['notify'] = labelencoder.fit_transform(test['notify'])\n",
    "\n",
    "# test = onehot_encoder.fit_transform(test)\n",
    "# test = pd.get_dummies(test,prefix_sep = '_',drop_first = True)\n",
    "\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test=lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_test=prediction_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution=pd.DataFrame(prediction_test,Id,columns=[\"target_days\"])\n",
    "print(my_solution.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_solution.to_csv(\"prediction21.csv\",index_label=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
