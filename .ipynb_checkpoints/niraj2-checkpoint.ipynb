{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "sns.set()\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train.head()\n",
    "\n",
    "\n",
    "train.isnull().sum()\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['subcategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train['opened_at'] = pd.to_datetime(train.opened_at)\n",
    "train['year'] = train['opened_at'].dt.year\n",
    "train['month'] = train['opened_at'].dt.month\n",
    "train['day'] = train['opened_at'].dt.day\n",
    "# train['dayofyear'] = train['opened_at'].dt.dayofyear\n",
    "# train['weekofyear'] = train['opened_at'].dt.weekofyear\n",
    "train['dayofweek'] = train['opened_at'].dt.dayofweek\n",
    "train['hour'] = train['opened_at'].dt.hour\n",
    "train['minute'] = train['opened_at'].dt.minute\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train.iterrows():\n",
    "    if(row['update_count']!=0):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['vendor']=='Vendor 1' or row['vendor']=='code 8s'):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['knowledge']=='True'):\n",
    "        train.drop(index,inplace=True)\n",
    "    if(row['made_sla']=='False'):\n",
    "        train.drop(index,inplace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,row in train.iterrows(): \n",
    "    if(row['target_days']>10):\n",
    "        train.drop(index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['vendor'], axis=1, inplace=True)\n",
    "train.drop(['reassignment_count'], axis=1, inplace=True)\n",
    "train.drop(['reopen_count'], axis=1, inplace=True)\n",
    "train.drop(['update_count'], axis=1, inplace=True)\n",
    "# train.drop(['assigned_to'], axis=1, inplace=True)\n",
    "train.drop(['opened_at'], axis=1, inplace=True)\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "train.drop(['made_sla'], axis=1, inplace=True)\n",
    "train.drop(['notify'], axis=1, inplace=True)\n",
    "# train.drop(['year'], axis=1, inplace=True)\n",
    "train.drop(['contact_type'], axis=1, inplace=True)\n",
    "# train.drop(['dayofweek'], axis=1, inplace=True)\n",
    "train.drop(['impact'], axis=1, inplace=True)\n",
    "train.drop(['urgency'], axis=1, inplace=True)\n",
    "# train.drop(['priority'], axis=1, inplace=True)\n",
    "# train.drop(['location'], axis=1, inplace=True)\n",
    "train.drop(['knowledge'], axis=1, inplace=True)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['OpBy','opby','opened_by1']] = train.opened_by.str.split(expand=True) \n",
    "train[['loc','location1']] = train.location.str.split(expand=True) \n",
    "train[['cat','category1']] = train.category.str.split(expand=True) \n",
    "train[['scat','subcategory1']] = train.subcategory.str.split(expand=True) \n",
    "train[['assg','assigned_to1']] = train.assigned_to.str.split(expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['OpBy'], axis=1, inplace=True)\n",
    "train.drop(['opby'], axis=1, inplace=True)\n",
    "train.drop(['opened_by'], axis=1, inplace=True)\n",
    "train['opened_by1'] = train['opened_by1'].astype(float)\n",
    "\n",
    "train.drop(['loc'], axis=1, inplace=True)\n",
    "train.drop(['location'], axis=1, inplace=True)\n",
    "train['location1'] = train['location1'].astype(float)\n",
    "\n",
    "train.drop(['cat'], axis=1, inplace=True)\n",
    "train.drop(['category'], axis=1, inplace=True)\n",
    "train['category1'] = train['category1'].astype(float)\n",
    "\n",
    "train.drop(['scat'], axis=1, inplace=True)\n",
    "train.drop(['subcategory'], axis=1, inplace=True)\n",
    "train['subcategory1'] = train['subcategory1'].astype(float)\n",
    "\n",
    "train.drop(['assg'], axis=1, inplace=True)\n",
    "train.drop(['assigned_to'], axis=1, inplace=True)\n",
    "train['assigned_to1'] = train['assigned_to1'].astype(float)\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[['impact1','imp']] = train['impact'].str.split('-',expand=True)\n",
    "# train.drop(['imp'], axis=1, inplace=True)\n",
    "# train.drop(['impact'], axis=1, inplace=True)\n",
    "# train['impact1'] = train['impact1'].astype(float)\n",
    "\n",
    "# train[['urgency1','urg']] = train['urgency'].str.split('-',expand=True)\n",
    "# train.drop(['urg'], axis=1, inplace=True)\n",
    "# train.drop(['urgency'], axis=1, inplace=True)\n",
    "# train['urgency1'] = train['urgency1'].astype(float)\n",
    "\n",
    "train[['priority1','pri']] = train['priority'].str.split('-',expand=True)\n",
    "train.drop(['pri'], axis=1, inplace=True)\n",
    "train.drop(['priority'], axis=1, inplace=True)\n",
    "train['priority1'] = train['priority1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetday = train.target_days[train.assigned_to== NULL]\n",
    "# assign = train.assigned_to1[train.target_days==targetday]\n",
    "# mapping = {i:j for i,j in zip(targetday,assign)}\n",
    "# for x in mapping:\n",
    "#     train.loc[train.target_days == x,'assigned_to1'] = mapping[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"assigned_to1\"] = train.groupby(\"target_days\").transform(lambda x: x.fillna(x.mode()))\n",
    "train[\"category1\"] = train.groupby(\"target_days\").transform(lambda x: x.fillna(x.mode()))\n",
    "train[\"subcategory1\"] = train.groupby(\"target_days\").transform(lambda x: x.fillna(x.mode()))\n",
    "train[\"location1\"] = train.groupby(\"target_days\").transform(lambda x: x.fillna(x.mode()))\n",
    "train[\"opened_by1\"] = train.groupby(\"target_days\").transform(lambda x: x.fillna(x.mode()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['assigned_to1']=train['assigned_to1'].fillna(125)\n",
    "# train['opened_by1']=train['opened_by1'].fillna(180)\n",
    "# train['location1']=train['location1'].fillna(93)\n",
    "# train['category1']=train['category1'].fillna(20)\n",
    "# train['subcategory1']=train['subcategory1'].fillna(125)\n",
    "\n",
    "#rain['category1'].fillna((train['category1'].value_counts().idxmax()), inplace=True)\n",
    "#train['subcategory1'].fillna((train['subcategory1'].value_counts().idxmax()), inplace=True)\n",
    "# train['opened_by1'].fillna((train['opened_by1'].value_counts().idxmax()), inplace=True)\n",
    "# train['location1'].fillna((train['location1'].value_counts().idxmax()), inplace=True)\n",
    "# train['assigned_to1'] = train['assigned_to1'].convert_objects(convert_numeric=True).fillna(125)\n",
    "#train['assigned_to1'] = train['assigned_to1'].convert_objects(convert_numeric=True).fillna(125)\n",
    "# train['category1'].interpolate(method ='linear', limit_direction ='forward') \n",
    "# train['subcategory1'].interpolate(method ='linear', limit_direction ='forward') \n",
    "# train['opened_by1'].interpolate(method ='linear', limit_direction ='forward') \n",
    "# train['location1'].interpolate(method ='linear', limit_direction ='forward') \n",
    "# train['assigned_to1'].interpolate(method ='linear', limit_direction ='forward') \n",
    "# train.interpolate(method ='index', limit_direction ='forward') \n",
    "# train.interpolate(method ='index', limit_direction ='backward') \n",
    "\n",
    "train = train.dropna(axis = 0, how ='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#train['made_sla'] = labelencoder.fit_transform(train['made_sla'])\n",
    "# train['assigned_to'] = labelencoder.fit_transform(train['assigned_to'])\n",
    "# train['vendor'] = labelencoder.fit_transform(train['vendor'])\n",
    "# train['contact_type'] = labelencoder.fit_transform(train['contact_type'])\n",
    "#train['knowledge'] = labelencoder.fit_transform(train['knowledge'])\n",
    "# train['notify'] = labelencoder.fit_transform(train['notify'])\n",
    "\n",
    "# onehot_encoder = OneHotEncoder(sparse=False)\n",
    "# train = onehot_encoder.fit_transform(train)\n",
    "\n",
    "# train = pd.get_dummies(train,prefix_sep = '_',drop_first = True)\n",
    "\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"prepros.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = train[\"target_days\"]\n",
    "\n",
    "X = train.drop([\"target_days\"],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train , x_test, y_train, y_test = train_test_split(X,y,test_size=0.0005,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.svm import SVC\n",
    "# lr = SVC(kernel = 'linear',C=1000)\n",
    "# lr = RandomForestRegressor(bootstrap=True,n_estimators=1810)\n",
    "\n",
    "# lr.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "estimators = np.arange(10, 1500, 200)\n",
    "scores = []\n",
    "for n in estimators:\n",
    "    lr.set_params(n_estimators=n)\n",
    "    lr.fit(X_train, y_train)\n",
    "    scores.append(lr.score(X_test, y_test))\n",
    "plt.title(\"Effect of n_estimators\")\n",
    "plt.xlabel(\"n_estimator\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.plot(estimators, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error,r2_score\n",
    "y_pred= lr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "lmse = mean_squared_log_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "lrmse = np.sqrt(lmse)\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"LMSE:\", lmse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"LRMSE:\", lrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "test['opened_at'] = pd.to_datetime(test.opened_at)\n",
    "test['year'] = test['opened_at'].dt.year\n",
    "test['month'] = test['opened_at'].dt.month\n",
    "test['day'] = test['opened_at'].dt.day\n",
    "# test['dayofyear'] = test['opened_at'].dt.dayofyear\n",
    "# test['weekofyear'] = test['opened_at'].dt.weekofyear\n",
    "test['dayofweek'] = test['opened_at'].dt.dayofweek\n",
    "test['hour'] = test['opened_at'].dt.hour\n",
    "test['minute'] = test['opened_at'].dt.minute\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = test['Id']\n",
    "\n",
    "test.drop(['vendor'], axis=1, inplace=True)\n",
    "test.drop(['reassignment_count'], axis=1, inplace=True)\n",
    "test.drop(['reopen_count'], axis=1, inplace=True)\n",
    "test.drop(['update_count'], axis=1, inplace=True)\n",
    "# test.drop(['assigned_to'], axis=1, inplace=True)\n",
    "test.drop(['opened_at'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['made_sla'], axis=1, inplace=True)\n",
    "test.drop(['notify'], axis=1, inplace=True)\n",
    "# test.drop(['year'], axis=1, inplace=True)\n",
    "test.drop(['contact_type'], axis=1, inplace=True)\n",
    "# test.drop(['dayofweek'], axis=1, inplace=True)\n",
    "test.drop(['knowledge'], axis=1, inplace=True)\n",
    "# test.drop(['location'], axis=1, inplace=True)\n",
    "test.drop(['impact'], axis=1, inplace=True)\n",
    "test.drop(['urgency'], axis=1, inplace=True)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['OpBy','opby','opened_by1']] = test.opened_by.str.split(expand=True) \n",
    "test[['loc','location1']] = test.location.str.split(expand=True) \n",
    "test[['cat','category1']] = test.category.str.split(expand=True) \n",
    "test[['scat','subcategory1']] = test.subcategory.str.split(expand=True) \n",
    "test[['assg','assigned_to1']] = test.assigned_to.str.split(expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['OpBy'], axis=1, inplace=True)\n",
    "test.drop(['opby'], axis=1, inplace=True)\n",
    "test.drop(['opened_by'], axis=1, inplace=True)\n",
    "test['opened_by1'] = test['opened_by1'].astype(float)\n",
    "\n",
    "test.drop(['loc'], axis=1, inplace=True)\n",
    "test.drop(['location'], axis=1, inplace=True)\n",
    "test['location1'] = test['location1'].astype(float)\n",
    "\n",
    "test.drop(['cat'], axis=1, inplace=True)\n",
    "test.drop(['category'], axis=1, inplace=True)\n",
    "test['category1'] = test['category1'].astype(float)\n",
    "\n",
    "test.drop(['scat'], axis=1, inplace=True)\n",
    "test.drop(['subcategory'], axis=1, inplace=True)\n",
    "test['subcategory1'] = test['subcategory1'].astype(float)\n",
    "\n",
    "test.drop(['assg'], axis=1, inplace=True)\n",
    "test.drop(['assigned_to'], axis=1, inplace=True)\n",
    "test['assigned_to1'] = test['assigned_to1'].astype(float)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test[['impact1','imp']] = test['impact'].str.split('-',expand=True)\n",
    "# test.drop(['imp'], axis=1, inplace=True)\n",
    "# test.drop(['impact'], axis=1, inplace=True)\n",
    "# test['impact1'] = test['impact1'].astype(float)\n",
    "\n",
    "# test[['urgency1','urg']] = test['urgency'].str.split('-',expand=True)\n",
    "# test.drop(['urg'], axis=1, inplace=True)\n",
    "# test.drop(['urgency'], axis=1, inplace=True)\n",
    "# test['urgency1'] = test['urgency1'].astype(float)\n",
    "\n",
    "test[['priority1','pri']] = test['priority'].str.split('-',expand=True)\n",
    "test.drop(['pri'], axis=1, inplace=True)\n",
    "test.drop(['priority'], axis=1, inplace=True)\n",
    "test['priority1'] = test['priority1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\test['category1'].fillna((test['category1'].value_counts().idxmax()), inplace=True)\n",
    "#test['subcategory1'].fillna((test['subcategory1'].value_counts().idxmax()), inplace=True)\n",
    "#test['opened_by1'].fillna((test['opened_by1'].value_counts().idxmax()), inplace=True)\n",
    "#test['location1'].fillna((test['location1'].value_counts().idxmax()), inplace=True)\n",
    "# test['assigned_to1']=test['assigned_to1'].fillna(125)\n",
    "# test['opened_by1']=test['opened_by1'].fillna(180)\n",
    "# test['location1']=test['location1'].fillna(93)\n",
    "# test['category1']=test['category1'].fillna(20)\n",
    "# test['subcategory1']=test['subcategory1'].fillna(125)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"assigned_to1\"] = test.groupby(\"location1\").transform(lambda x: x.fillna(x.mode()))\n",
    "test[\"category1\"] = test.groupby(\"location1\").transform(lambda x: x.fillna(x.mode()))\n",
    "test[\"subcategory1\"] = test.groupby(\"location1\").transform(lambda x: x.fillna(x.mode()))\n",
    "test[\"location1\"] = test.groupby(\"location1\").transform(lambda x: x.fillna(x.mode()))\n",
    "test[\"opened_by1\"] = test.groupby(\"location1\").transform(lambda x: x.fillna(x.mode()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "\n",
    "#test['made_sla'] = labelencoder.fit_transform(test['made_sla'])\n",
    "# test['contact_type'] = labelencoder.fit_transform(test['contact_type'])\n",
    "\n",
    "# train['assigned_to'] = labelencoder.fit_transform(train['assigned_to'])\n",
    "# train['vendor'] = labelencoder.fit_transform(train['vendor'])\n",
    "#test['knowledge'] = labelencoder.fit_transform(test['knowledge'])\n",
    "# test['notify'] = labelencoder.fit_transform(test['notify'])\n",
    "\n",
    "# test = onehot_encoder.fit_transform(test)\n",
    "# test = pd.get_dummies(test,prefix_sep = '_',drop_first = True)\n",
    "\n",
    "test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test=lr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test=prediction_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution=pd.DataFrame(prediction_test,Id,columns=[\"target_days\"])\n",
    "print(my_solution.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution.to_csv(\"prediction21.csv\",index_label=[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solution['target_days'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
